{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81777901-c980-4be3-be49-ec9283f1a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ad00b2d-78f0-4fc7-bd4e-b61175bbe346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f430e8d4-5208-44ff-bfe4-316cf5c9cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31f773a8-5999-493a-8b2d-a7d43be63c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_file(file_path, columns):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5f66c97-77fe-4fd5-83ff-0a232ab14ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"scifact/corpus.jsonl\"\n",
    "queries_file = \"scifact/queries.jsonl\"\n",
    "\n",
    "corpus_data = load_jsonl_file(corpus_file, [\"_id\", \"title\", \"text\"])\n",
    "queries_data = load_jsonl_file(queries_file, [\"_id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e1ad262-cc5c-48bb-9b4a-6b999adac779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_documents(include_title=True):\n",
    "    if include_title:\n",
    "        corpus_data[\"full_text\"] = corpus_data[\"title\"] + \" \" + corpus_data[\"text\"]\n",
    "    else:\n",
    "        corpus_data[\"full_text\"] = corpus_data[\"text\"]\n",
    "    return corpus_data[\"full_text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826b4da-e7cb-4050-9a45-60e75d6407bb",
   "metadata": {},
   "source": [
    "# Define the BERT Retriever Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92f31fb8-db85-4bf6-bf79-ff4cb522760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTRetriever:\n",
    "    def __init__(self):\n",
    "        # Load the pre-trained BERT model for sentence embeddings\n",
    "        print(\"Loading BERT model...\")\n",
    "        self.model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "        print(\"Model loaded.\")\n",
    "\n",
    "    def encode(self, texts, batch_size=64):\n",
    "        \"\"\"\n",
    "        Convert a list of texts (sentences or documents) into BERT embeddings.\n",
    "        Returns a NumPy array of shape (num_texts, embedding_size).\n",
    "        \"\"\"\n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        return embeddings\n",
    "\n",
    "    def index_documents(self, documents):\n",
    "        \"\"\"\n",
    "        Store the documents and compute their embeddings using BERT.\n",
    "        \"\"\"\n",
    "        self.documents = documents                      # Store original texts\n",
    "        self.document_ids = list(range(len(documents))) # Assign each a numeric ID\n",
    "        self.document_embeddings = self.encode(documents) # Get embeddings\n",
    "        return self.document_embeddings\n",
    "\n",
    "    def search(self, query, top_k=100):\n",
    "        \"\"\"\n",
    "        Search for the top_k most similar documents to the given query.\n",
    "        Returns a list of (document_id, similarity_score) tuples.\n",
    "        \"\"\"\n",
    "        # Convert query into embedding\n",
    "        query_embedding = self.encode([query])[0]\n",
    "\n",
    "        # Compute cosine similarity between query and all documents\n",
    "        cosine_scores = util.cos_sim(query_embedding, self.document_embeddings)[0]\n",
    "        cosine_scores = cosine_scores.cpu().numpy()\n",
    "\n",
    "        # Create a list of (document_id, score) pairs\n",
    "        results = []\n",
    "        for i in range(len(cosine_scores)):\n",
    "            results.append((self.document_ids[i], float(cosine_scores[i])))\n",
    "\n",
    "        # Sort the results by score in descending order\n",
    "        for i in range(len(results)):\n",
    "            for j in range(i + 1, len(results)):\n",
    "                if results[j][1] > results[i][1]:\n",
    "                    results[i], results[j] = results[j], results[i]\n",
    "\n",
    "        # Return top_k results\n",
    "        return results[:top_k]\n",
    "\n",
    "    # We can use this if we want to rerank based on the initial results from assignment 1\n",
    "    def rerank(self, query, initial_results, documents):\n",
    "        \"\"\"Rerank initial results using BERT embeddings.\"\"\"\n",
    "        doc_ids = [doc_id for doc_id, _ in initial_results]\n",
    "        docs_to_rerank = [documents[doc_id] for doc_id in doc_ids]\n",
    "        \n",
    "        query_embedding = self.encode([query])[0]\n",
    "        doc_embeddings = self.encode(docs_to_rerank)\n",
    "        \n",
    "        similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "        \n",
    "        reranked = []\n",
    "        for i in range(len(similarities)):\n",
    "            reranked.append((doc_ids[i], similarities[i]))\n",
    "    \n",
    "        reranked.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "        return reranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4106937-6f2c-4110-b7fd-f08837eaf2c8",
   "metadata": {},
   "source": [
    "# Format and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa851c38-df71-4002-bae6-b747820d6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(results, document_ids, documents):\n",
    "    \"\"\"\n",
    "    Convert search results into a readable format with doc_id, score, and text.\n",
    "    \"\"\"\n",
    "    formatted_results = []\n",
    "\n",
    "    for result in results:\n",
    "        doc_index = result[0]\n",
    "        score = result[1]\n",
    "        text = documents[doc_index]\n",
    "        doc_id = document_ids[doc_index]\n",
    "\n",
    "        formatted_results.append({\n",
    "            \"doc_id\": doc_id,\n",
    "            \"score\": f\"{score:.4f}\",\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68b5385a-6fb2-4af4-9f6c-dc1d6f33675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load and prepare data\n",
    "    documents = get_all_documents()\n",
    "    document_ids = []\n",
    "\n",
    "    for doc_id in corpus_data[\"_id\"].tolist():\n",
    "        document_ids.append(int(doc_id))\n",
    "\n",
    "    queries = queries_data[\"text\"].tolist()\n",
    "    query_ids = []\n",
    "\n",
    "    for query_id in queries_data[\"_id\"].tolist():\n",
    "        query_ids.append(int(query_id))\n",
    "\n",
    "    # Initialize and index documents using BERT\n",
    "    retriever = BERTRetriever()\n",
    "    retriever.index_documents(documents)\n",
    "\n",
    "    # Open result file for writing\n",
    "    with open(\"res/a2_res_BERT.txt\", \"w\") as file:\n",
    "        file.write(\"query_id\\tQ0\\tdoc_id\\trank\\tscore\\ttag\\n\")\n",
    "\n",
    "    # Process each query and retrieve top documents\n",
    "    for i in range(len(queries)):\n",
    "        query = queries[i]\n",
    "        query_id = query_ids[i]\n",
    "\n",
    "        results = retriever.search(query)\n",
    "        formatted_results = format_results(results, document_ids, documents)\n",
    "\n",
    "        # Append each result to the output file\n",
    "        with open(\"res/a2_res_BERT.txt\", \"a\") as file:\n",
    "            for rank in range(len(formatted_results)):\n",
    "                result = formatted_results[rank]\n",
    "                doc_id = result[\"doc_id\"]\n",
    "                score = result[\"score\"]\n",
    "                tag = f\"tag_{query_id}_{doc_id}\"\n",
    "\n",
    "                file.write(f\"{query_id}\\tQ0\\t{doc_id}\\t{rank}\\t{score}\\t{tag}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247e06b-7b7f-48c4-945a-71edc6e8e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n",
      "Model loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9128ffdfb1eb4a33b1d03b9389e9cd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note \"Error displaying widget\" is just a warning for display. It can be ignored\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd4ffa-769a-4c15-919d-eadb0dd05643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
